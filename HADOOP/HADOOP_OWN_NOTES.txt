HADOOP
------
SESSION 1 12TH NOV
------------------
1.what is big data ?
2.why Hadoop 
3.Drawbacks of database
4.Hadoop advantages
5.Hadoop components
6.Hadoop job market

----------------------------------------------------------------------------------------------------------------------------------------
Bigdata:KB,MB,GB      TB,PB,EB,ZB,YB,SB..................

1PB=1024TB's

SBI=>LAKHS

FB---->1 min ----

----------------------------------------------------------------------------------------------------------------------------------------
on an average
1.Google generaating -------------------->450PB/month
2.FaceBook generating-------------------->350PB/month
										  350*1024TB's


----------------------------------------------------------------------------------------------------------------------------------------
Oracle,MySQL,sqlserver------------------->OLTP--->GB's
Teradata,Natezza,Vertica----------------->OLAP--->TB's

1PB of data ----------->no tool 

----------------------------------------------------------------------------------------------------------------------------------------
Drawbacks of Databases:

1.Limited storage :GB's or TB's 
2.no parallel processing
3.if volume increases -------------------->speed decreases
   eg: select sum(amt) from sales1; ---------->1000 recs
       select sum(amt) from sales2; ---------->1Lakh recs
       select sum(amt) from sales3; ---------->1 cr recs
4.if complexity increases speed decreases	

  eg: select sum(amt) from sales1;
	  select avg(amt) from sales1;
	  select stddev(amt) from sales1;

5.RDBMS can handle only structured data.

	   
----------------------------------------------------------------------------------------------------------------------------------------
Hadoop Cluster : Group of cpu's(nodes) connected in a n/w
               There are 2 types of nodes
			   i)Master nodes or Name node
			  ii)Name node or Data node

Master node responsibilities
----------------------------
1.Task Assignment
2.Load balancing
3.Fault tolerence
4.Health monitor
			  
Slave node responsibilities
---------------------------
1.Storing and processing the data			  
			   
			   
----------------------------------------------------------------------------------------------------------------------------			   

Hadoop Advantages:

1.Unlimited data storage----->horizantally unlimited scalability
2.High speed processing------>parallel processing
3.can handle all varieties of data
4.opensource-------->No licensing required			   
			   
			   
----------------------------------------------------------------------------------------------------------------------------------------
SESSION 2 13th NOV
------------------
OLTP--->online transcational processing

Hadoop Components
-----------------
1.HDFS------------------------------>Storage
2.MapReduce------------------------->Processing
3.PIG------------------------------->Processing,PigLatin
4.Hive------------------------------>Processing,DWH,hql-------->sql
5.Sqoop---------------------------->sql+hadoop--------->import/export operations
6.NoSql: Schemaless
		 Random access
   Nosql database-------->Hbase,casandra,Mondgodb,,couvhdg,Riak,PNUT

7.HBase:
8.Flume --------> Streaming components ---->for streaming
9.Kafka---------->for Advanced streaming
10.YARN:
11.ZooKeeper
-----------------------------------------------------------------------------------------------------------------------------
Data storage and processing in Hadoop:

In Hadoop , Data stored in the form of files

Each file again sub-devided into blocks

default blocksize =64mb

Design principle w.r.to HDFS blocks

1.Every file has will have dedicated no of blocks
2.No two files data is stored in a single blocks
3.All the blocks have equal volume except the last block

----------------------------------------------------------------------------------------------------------------------------
SESSION 3 14th NOV
------------------

CASE 1 : No of blocks = No of slaves(B1,B2,B3,B4) (S1,S2,S3,S4)--->Then more parallelism
CASE 2 : No of blocks > No of slaves(B1,B2,B3,B4) (S1,S2)--->Then less parallelism
CASE 3 : More no of blocks ---> one slaves (B1,B2,B3,B4) (S1)--->Then no parallelism


Replication and Fault tolerence

4 step criteria

1.Name node select the slave which is highly configured
2.Name node select which is nearest
3.Name node select the slave which is more idle
4.Name node slect the slave with good health



----------------------------------------------------------------------------------------------------------------------------------------

SESSION 4 15th NOV
------------------

Design principules w.r.to replication

1.Replication applicable only to data but not for metadata
2.Replication applicable only for data node but not for name node
3.Maximum no of replication depends on the no of slave nodes
4.All the replicas can not be stored in the same slave

---------------------------------------------------------------------------------------------------------------------------
Configuring Block size and Replication

goto the hadoop installed directory ------->hadoop/conf/hdfs-site.xml

open this hdfs-site.xml

<configuration>
     <property>
	    <name>dfs.Block.size</name>
		<value>50mb</value>
	</property>
    <property>	
	    <name>dfs.replication</name>
		<value>4</value>
    </property>		
</configuration>

----------------------------------------------------------------------------------------------------------------------------

Note:If we are changing the block size then we need to restart the cluster,then only the changes will be applied.bcoz the
config file is read only once i.e during the start of the custer


SESSION 5 16th NOV
------------------

Hadoop Architecture
------------------

1.Storage Architectural components
2.processing Architectural components

Name node responsiblilites
--------------------------
1.To store the physical memory locations of the blocks of a file
2.By combining which physical memory locations of the block so that the file can be formulated 
3.To store metadata(data about data) information

Data node responsiblilites
--------------------------
1.Storing HDFS blocks.we can have multiple data nodes.the no of data nodes depends on the voume of the data.

Secondary name node
-------------------
if name node down then entire cluster is down then entire cluster will be in spectator mode means can not perform any
operation such as storage and processing.if name node is down then immidiately secondary name node comes into picture

Secondary name node responsibilities
------------------------------------
same as name node
but secondary name node is not 100% backup node for name node.
bcoz name node can read write and update but secondary name node can only read but cannot write or update

what happens internally within name node
----------------------------------------
Eevery node int the cluster will have 2 sections one is LFS and second one is HDFS
all the metadata info stored in HDFS of name node in form of blocks only.
this metadata also stored in temp folder of LFS
form this temp folder in a timely manner copied in to 2 special files 1.fsimage 2.edits
only name node can write in to fsimage and edits secondary name node can not write into fsimage and edits















-----------------------------------------------------------------------------------------------------------------------------

SESSION 8 21ST NOV
------------------
Hadoop is meant for storage and processing.For storage we are going with HDFS(Hadoop Distributed File System) and for processing
we are going with Map Reduce.

HDFS has three components

-Name Node
-Data Node
-Secondary Name Node

Map Reduce has 2 components

-Job Tracker
-Task Tracker

Within the Name Node we will have Job Tracker
Within the Data Node we will have Task Tracker
Job Tracker assigns task to Task Tracker and Task Tracker performs the tasks

-who is going to devide the file into blocks and store in slaves ?
 Name Node
-Who devides the job into tasks 
 Job Tracker
-who is going to executes the the tasks
 Task Tracker 


 
 ---------------------------------------------------------------------------------------------------------------------------------------
 SESSION 21 11th DEC
 -------------------
