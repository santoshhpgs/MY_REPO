HADOOP
------
SESSION 1 12TH NOV
------------------
1.what is big data ?
2.why Hadoop 
3.Drawbacks of database
4.Hadoop advantages
5.Hadoop components
6.Hadoop job market

----------------------------------------------------------------------------------------------------------------------------------------
Bigdata:KB,MB,GB      TB,PB,EB,ZB,YB,SB..................

1PB=1024TB's

SBI=>LAKHS

FB---->1 min ----

----------------------------------------------------------------------------------------------------------------------------------------
on an average
1.Google generaating -------------------->450PB/month
2.FaceBook generating-------------------->350PB/month
										  350*1024TB's


----------------------------------------------------------------------------------------------------------------------------------------
Oracle,MySQL,sqlserver------------------->OLTP--->GB's
Teradata,Natezza,Vertica----------------->OLAP--->TB's

1PB of data ----------->no tool 

----------------------------------------------------------------------------------------------------------------------------------------
Drawbacks of Databases:

1.Limited storage :GB's or TB's 
2.no parallel processing
3.if volume increases -------------------->speed decreases
   eg: select sum(amt) from sales1; ---------->1000 recs
       select sum(amt) from sales2; ---------->1Lakh recs
       select sum(amt) from sales3; ---------->1 cr recs
4.if complexity increases speed decreases	

  eg: select sum(amt) from sales1;
	  select avg(amt) from sales1;
	  select stddev(amt) from sales1;

5.RDBMS can hold only structured data.

6.	  
	   
----------------------------------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------------------------------



SESSION 8 21ST NOV
------------------
Hadoop is meant for storage and processing.For storage we are going with HDFS(Hadoop Distributed File System) and for processing
we are going with Map Reduce.

HDFS has three components

-Name Node
-Data Node
-Secondary Name Node

Map Reduce has 2 components

-Job Tracker
-Task Tracker

Within the Name Node we will have Job Tracker
Within the Data Node we will have Task Tracker
Job Tracker assigns task to Task Tracker and Task Tracker performs the tasks

-who is going to devide the file into blocks and store in slaves ?
 Name Node
-Who devides the job into tasks 
 Job Tracker
-who is going to executes the the tasks
 Task Tracker 


 
 ---------------------------------------------------------------------------------------------------------------------------------------
 SESSION 21 11th DEC
 -------------------
 PIG is a component of Hadoop used for processing
 PIG is a dataflow language
 Dataflow is a sequence collections of pipes.
 A pipe is any data operation such as loading data,trasnforming data,filtering data,sorting data,merging data,grouping data etc.
 PIG processing happens using various built in operators