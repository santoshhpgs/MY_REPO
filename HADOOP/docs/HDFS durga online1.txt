HDFS commands:

Before we start with HDFS commands, we need to start the storage and processing components

Starting the storage components(daemons)------>start-dfs.sh
Starting the processing components(daemons)--->start-yarn.sh

Every hdfs command starts with

hadoop fs -commandname

ex:

1)hadoop fs -ls / ------->displays all files and directories of hdfs

2)hadoop fs -mkdir /dirname---->for creating a hdfs directory

we cannot create files in HDFS as changes or modifications are not allowed,
so always we need to bring data(files) from LFS to HDFS

so for bringing data(files) from LFS to HDFS , we have a command called 

3)put (or) copyFromLocal :   LFS------------>HDFS

syntax:  hadoop fs -put LFSsourcepath  HDFSdestinationpath
                            (or)
         hadoop fs -copyFromLocal LFSsoucepath HDFSdestinationpath

put command performs the following :

1)copies a LFSfile into HDFSdirectory
$ hadoop fs -put sample3.txt /hdfsdir1
lenovo@lenovo-Lenovo-G450:~$ hadoop fs -ls /hdfsdir1
Found 2 items
-rw-r--r--   1 lenovo supergroup          0 2018-11-29 08:47 /hdfsdir1/sample1.txt
-rw-r--r--   1 lenovo supergroup         94 2018-11-29 08:48 /hdfsdir1/sample3.txt
lenovo@lenovo-Lenovo-G450:~$ hadoop fs -cat /hdfsdir1/sample3.txt
Hadoop is simple
Hadoop is Great
Hadoop is booming
Hadoop is easyJava is simple


2)copies multiple LFSfiles into HDFSdirectory

$ hadoop fs -copyFromLocal *.java /hdfsdir1

3)copies a LFSfile into hdfs

$ hadoop fs -put sample4.txt /
lenovo@lenovo-Lenovo-G450:~$ hadoop fs -cat /sample4.txt
Good Morning.....
Good Morning.....
Good Morning.......
Good Morning......
Good Morning......
Hello.....Hyd...
Hello.....Hyd...


4)copies a LFSfile into HDFSfile
 hadoop fs -put sample6.txt /hdfsdir1/demo1.txt

here demo1.txt created automatically and sample6.txt data copied into it.

5)copies a LFSdirectory into HDFSdirectory
 hadoop fs -copyFromLocal lfslab1 /hdfsdir1

------------------------------------------------------------------------------------------------------
3)get (or) copyToLocal : copying data(files) HDFS------------>LFS
syntax:  hadoop fs -get /HDFSsourcepath  LFSdestinationpath
                            (or)
         hadoop fs -copyToLocal /HDFSsoucepath LFSdestinationpath

get command performs the following :

1)copies a HDFSfile into LFSdirectory
$ hadoop fs -copyToLocal /hdfsdir1/sample3.txt lfsdir1
lenovo@lenovo-Lenovo-G450:~$ ls lfsdir1
sample3.txt
lenovo@lenovo-Lenovo-G450:~$ cat lfsdir1/sample3.txt
Hadoop is simple
Hadoop is Great
Hadoop is booming
Hadoop is easyJava is simple


2)copies multiple HDFSfiles into LFSdirectory

$ hadoop fs -copyToLocal /hdfsdir1/*.java  lfsdir1

lenovo@lenovo-Lenovo-G450:~$ ls lfsdir1
cust.java       edept.java  emp5.java      empdept.java     hemp1.java        samp2.java    std1.java       student.java
customer1.java  emp1.java   emp7.java      emp.java         marks1.java       sample1.java  std2.java
customer2.java  emp2.java   empdept1.java  empres1.java     mulgrp.java       sample3.txt   stdmarks1.java
customer.java   emp3.java   empdept2.java  hbasecust7.java  QueryResult.java  sqemp.java    stdmarks.java


3)copies a HDFSfile into LFSfile
$ hadoop fs -get /hdfsdir1/sample3.txt lfsdir1/sample40.txt


4)copies a HDFSdirectory into LFSdirectory
$ hadoop fs -get /hdfsdir1 lfsdir1

----------------------------------------------------------------------------------------------------------------
5)

-cp command : copy command

cp command is used to copy data from HDFS-------->HDFS or from LFS --------->LFS
                         but not for LFS-------->HDFS and vicversa

so cp is for copying data within a filesystem but not for copying data fron one filesystem to another 

syntax : hadoop fs -cp HDFSsourcepath HDFSdestinationpath


 cp command performs the following...
1)copies a hdfs file into hdfs dirctory
 hadoop fs -cp /hdfsdir1/sample3.txt /hdfsdir2


2)copies  multiple hdfsfiles into hdfsdirectory
$ hadoop fs -cp /hdfsdir1/*.java /hdfsdir2

3)copies a hdfsfile into another hdfsfile
$ hadoop fs -cp /hdfsdir1/sample3.txt /hdfsdir2/sample45.txt
here sample45.txt created automatically and data of sample3.txt copied into it

4)copies a hdfsdirectory into another hdfsdirectory.
$ hadoop fs -cp /hdfsdir1 /hdfsdir2
-----------------------------------------------------------------------------------------------------------------
6)

-mv command : move command

mv command is used to move data from HDFS-------->HDFS or from LFS --------->LFS
                         but not for LFS-------->HDFS and vicversa

so mv is for moving data within a filesystem but not for moving data fron one filesystem to another 

syntax : hadoop fs -mv HDFSsourcepath HDFSdestinationpath

mv command follows cut(ctrl+x) and paste(ctrl+v) i.e wont be available in source will be available in the
destination.

 mv command performs the following...
1)moves a hdfs file into hdfs dirctory
 hadoop fs -mv /hdfsdir1/sample3.txt /hdfsdir3


2)moves  multiple hdfsfiles into hdfsdirectory
$ hadoop fs -mv /hdfsdir1/*.java /hdfsdir3

3)moves a hdfsfile into another hdfsfile (alternatively used for renaming a file)
$ hadoop fs -mv /hdfsdir1/sample3.txt /hdfsdir1/demo3.txt


4)moves a hdfsdirectory into another hdfsdirectory.
$ hadoop fs -mv /hdfsdir2 /hdfsdir1

----------------------------------------------------------------------------------------------------------------
7)rm : for removing a hdfs file

syntax: hadoop fs -rm dirname/filename

ex: $ hadoop fs -rm /hdfsdir1/sample1.txt

----------------------------------------------------------------------------------------------------------------
8)rmdir : for removing a empty directory

$ hadoop fs -mkdir /hdfsdir2
lenovo@lenovo-Lenovo-G450:~$ hadoop fs -rmdir /hdfsdir2

------------------------------------------------------------------------------------------------------------
9)rm -r :removing a directory with content
$ hadoop fs -rm -r /hdfsdir1

------------------------------------------------------------------------------------------------------------
10)Compressing the data:

gzip :

$ cat sales.txt
hyd 2015 apr 35
pun 2015 may -25
ban 2015 jun 40
hyd 2016 apr 45
pun 2016 may -33
ban 2016 jun -43
hyd 2017 apr 44
pun 2017 may -51
ban 2017 jun 49
lenovo@lenovo-Lenovo-G450:~$ ll sales.txt
-rw-rw-r-- 1 lenovo lenovo 148 Jun 11 09:22 sales.txt
lenovo@lenovo-Lenovo-G450:~$ gzip sales.txt
lenovo@lenovo-Lenovo-G450:~$ cat sales.txt
cat: sales.txt: No such file or directory
lenovo@lenovo-Lenovo-G450:~$ cat sales.txt.gz
��[sales.txt˨LQ0204UH,(R06�*(̓�s+t�L���Y@�
                                                  �3��3�cc�3�]c�s��s�SC�s��\�֔lenovo@lenovo-Lenovo-G450:~$ 
lenovo@lenovo-Lenovo-G450:~$ ll sales.txt.gz
-rw-rw-r-- 1 lenovo lenovo 110 Jun 11 09:22 sales.txt.gz

bringing this zipped file to hdfs

~$ hadoop fs -mkdir /hdfsdir1
lenovo@lenovo-Lenovo-G450:~$ hadoop fs -put sales.txt.gz /hdfsdir1
lenovo@lenovo-Lenovo-G450:~$ hadoop fs -cat /hdfsdir1/sales.txt.gz
��[sales.txt˨LQ0204UH,(R06�*(̓�s+t�L���Y@�
                                                  �3��3�cc�3�]c�s��s�SC�s��\�֔lenovo@lenovo-Lenovo-G450:~$ 

------------------------------------------------------------------------------------------------------------
gunzip : for uncompressing 

$ cat sales.txt.gz
��[sales.txt˨LQ0204UH,(R06�*(̓�s+t�L���Y@�
                                                  �3��3�cc�3�]c�s��s�SC�s��\�֔lenovo@lenovo-Lenovo-G450:~$ 
lenovo@lenovo-Lenovo-G450:~$ gunzip sales.txt.gz
lenovo@lenovo-Lenovo-G450:~$ cat sales.txt
hyd 2015 apr 35
pun 2015 may -25
ban 2015 jun 40
hyd 2016 apr 45
pun 2016 may -33
ban 2016 jun -43
hyd 2017 apr 44
pun 2017 may -51
ban 2017 jun 49

But in HDFS ,we cannot uncompress but we can view the data in text format instead of compressed format
using a command called text command
$ hadoop fs -cat /hdfsdir1/sales.txt.gz
��[sales.txt˨LQ0204UH,(R06�*(̓�s+t�L���Y@�
                                                  �3��3�cc�3�]c�s��s�SC�s��\�֔
lenovo@lenovo-Lenovo-G450:~$ 
lenovo@lenovo-Lenovo-G450:~$ hadoop fs -text /hdfsdir1/sales.txt.gz
hyd 2015 apr 35
pun 2015 may -25
ban 2015 jun 40
hyd 2016 apr 45
pun 2016 may -33
ban 2016 jun -43
hyd 2017 apr 44
pun 2017 may -51
ban 2017 jun 49
--------------------------------------------------------------------------------------------------------------
11) du :disk usage: displays the size of each file in a directory

$ hadoop fs -ls /hdfsdir1
Found 2 items
-rw-r--r--   1 lenovo supergroup        110 2018-12-03 08:45 /hdfsdir1/sales.txt.gz
-rw-r--r--   1 lenovo supergroup        111 2018-12-03 08:56 /hdfsdir1/sample4.txt
lenovo@lenovo-Lenovo-G450:~$ hadoop fs -du /hdfsdir1
110  /hdfsdir1/sales.txt.gz
111  /hdfsdir1/sample4.txt

--------------------------------------------------------------------------------------------------------------
12)count : it displays no of directories , no of files and size occupied by all the files

hadoop fs -count /hdfsdir1
           1            2                221 /hdfsdir1

--------------------------------------------------------------------------------------------------------------

GUI:

http://localhost:50070

utilities------->browse the file system--> 
          /hdfsdir1 -->go
         displays all files within hdfsdir1

---------------------------------------------------------------------------------------------------------------

























